import urllib
from bs4 import BeautifulSoup
import requests


class AnalyzeTimeStamps:
    def __init__(self, xforce_api_key):
        self.api_key = xforce_api_key
        self.xforce_url = "https://api.xforce.ibmcloud.com/vulnerabilities/search/"

    def fetch_xforce_timestamp(self, cve_no):
        headers = {
            'Accept': 'application/json',
            'Authorization': 'Basic ' + self.api_key,
        }
        response = requests.get(self.xforce_url + cve_no, headers=headers)
        if response.status_code is 200:
            json_obj = response.json()[0]
            return json_obj['reported'][:10]
        else:
            return None

    @staticmethod
    def fetch_version_timestamp(os, package, package_version):
        """
        Get the date for when a particular version of the package was published
        """
        if os.startswith("ubuntu"):
            url = "https://launchpad.net/ubuntu/+source/" + package + "/+publishinghistory"
        elif os.startswith("debian"):
            url = "https://launchpad.net/debian/+source/" + package + "/+publishinghistory"
        else:
            return None
        req = urllib.request.urlopen(url)
        html_doc = req.read().decode('utf-8')
        soup = BeautifulSoup(html_doc, 'html.parser')
        data_table_rows = soup.find("table", attrs={"class": "listing"}).find("tbody").find_all("tr")
        published_date = ''
        # For each published version history, check for the version and return published date
        for row in data_table_rows:
            cells = row.find_all("td")
            for cell in cells:
                cell_version = cell.get_text().strip()
                if cell_version == package_version:
                    cell_date = cells[1].get_text()
                    cell_status = cells[2].get_text()
                    if cell_date and cell_status != "Deleted":
                        published_date = cell_date
                        return published_date[:10]
        return published_date[:10]
